\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{EdgeNet: SqueezeNet like Convolution Neural Network on Embedded FPGA\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{
\IEEEauthorblockN{Kathirgamaraja Pradeep}
\IEEEauthorblockA{\textit{University of Moratuwa} \\
deep0kathir@gmail.com}
\and
\IEEEauthorblockN{Kamalakkannan Kamalavasan}
\IEEEauthorblockA{\textit{University of Moratuwa} \\
kkvasan@live.com}
\and
\IEEEauthorblockN{Ratnasegar Natheesan}
\IEEEauthorblockA{\textit{University of Moratuwa} \\
rnatheesan@gmail.com}

}

\maketitle

\begin{abstract}
In recent years, Convolution Neural Network (CNN) gained great success in many application specially in computer vision. Now adapting CNN inference on edge device have became the active research in embedded vision and hot topic in Edge AI. The major design hurdles for implementing CNN inference on embedded systems are limited computation resource, memory resource and power budget. In this study we are presenting a novel architecture for SqueezeNet like CNN models and this can be extended to support any CNN model as well. We address two approaches to mitigate resource constraints. First, we use custom floating point(12 bit for computation and 8bit for storing). Second is slicing the model into repetitive block called computation blocks. We have implemented SqueezeNet v1.1 for Image-Net for large scale classification which achieved around 9 FPS at 100MHz. Accuracy loss due to using custom float is measured to be less than 2\%. Unlike other implementations which use FPGA boards with large amount of resources, our experiments are done in DE10 Nano, this mimics actual embedded system like environment.

\end{abstract}

\begin{IEEEkeywords}
FPGA, SqueezeNet, Convolution Neural Network,  Edge AI,  Embedded FPGA
\end{IEEEkeywords}

\section{Introduction}
This document is a model and instructions for \LaTeX.
Please observe the conference page limits. 

\section{Background}

\subsection{Convolution neural Network}
\subsection{SqueezeNet v1.1}
\subsection{Related work}


\section{Design Statergy}
Hardware resources(LUT, register, etc), on-chip memory or BRAM, bandwidth to access external memory and latency of systems are major constraints in embedded system. Typical CNN models used in computer vision task usually demand huge floating point arithmetic operations and large size of storage for parameters which cannot be stored in on-chip memory. So we cannot deploy entire model in hardware at once. At the same time it is not efficient to deploy single layer by layer, because each layer output should be stored and read back from memory and this will drastically degrade performance. We have carefully designed the architecture using two strategies, using custom floating point representation and computation blocks, such that any of the mentioned constraints will not badly affect the overall performance.  We also use techniques like double buffering, prefetching and pipelining to further improve the performance. 

\subsection{Strategy I: Custom floating point number
}\label{AA}
Most of CNN inference are implemented in 32 bit float numbers. For some application 32 bit precision is too much and we can save resource and power by using low bit with representations. we use two type of floating point representation, 12 bit representation is for computation and 8 bit representation for storing input, parameters and intermediate results. 8 bit representation used 5 bit exponent and 2 bit mantissa and 12 bit uses 5 bit exponent and 6 bit mantissa. This floating point representation is chosen by an empirical study on SqueezeNet model with different format. We only sacrifice 2\% of accuracy which gives top 1 accuracy of 70\% on ImageNet dataset, enough for most of embedded vision applications. We also can easily adapt any floating format according to modelâ€™s requirement and resource availability. 
Using 8 bit for model parameter save 75\% of memory required for model parameters. Using 12 bit operation save ???\% of hardware resources compare to 32 bit operation


\begin{table}[htbp]
\caption{Floating point resource comparision}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
&\multicolumn{2}{|c|}{\textbf{12 bit}} &\multicolumn{2}{|c|}{\textbf{32 bit}}\\
\cline{2-5} 
 & \textbf{\textit{ALM}} & \textbf{\textit{Register}}& \textbf{\textit{ALM}}& \textbf{\textit{Register}}\\
\hline
Addition& 131 & 109 & ??? & ???  \\
\hline
Multiplication& 43 & 45 & ??? & ???  \\
\hline
\end{tabular}
\label{tab1}
\end{center}
\end{table}



\subsubsection{Advantage of using custom floating point
}
Using 32 bit floating operation are not affordable in embedded systems. Studies [x,y,z] uses alternative representations like fixed point number, dynamic fixed point numbers(papers). When using fixed point intermediate output range may change drastically and designer have to be very careful about saturation values. In dynamic fixed point, its needed to adjust fractional part, which will consume additional resources. When using custom floating point numbers, user no need to worry much about the intermediate results saturation, because floating numbers can represent large range of numbers compare to range of fixed point representation of same size. 




\subsection{Strategy II: Computation block}
Computation block is the key feature in our design. It is a collection of layers fused together as single block. It contains expand layers(3x3, 1x1 convolution) followed by maxpool, squeeze layer(1x1 convolution) and finally average pool layer. With all these layers computation block will easily fit into any small FPGA like cyclone V. figure?? Show how squeezenet is sliced into 9 partition which can be executed in our computation block in sequential manner without reprogramming the hardware. Here is the list of main features of computation blocks

\begin{itemize}
\item Configurable size: size of input dimension, number of kernels can be configured on fly by setting configuration registers and computation block will operate accordingly. This make computation block can be reused for different size of input and number of kernel within provided range.

\item Configurable layers: layers in side computation block can be enabled or disabled through control signal or by API. This make computation blocks to operate in different mode. For example at start of SqueezeNet model, only 3x3 convolution  is enabled and at the end, only 3x3 and average pool are enabled.

\item Low memory footprint: computation block won't begin with squeeze layer as in fire module of SqueezeNet. We purposely did this because, after squeeze layer, model shirks to fewer size, so slicing the model after squeeze layer and making it as entry and exit point of the computation block will reduce memory access. And the intermediate results after expand layer, which are larger in size, are processed internally without sending to memory. This cleaver decision have enormously reduced the memory bandwidth demand. 

\item Cascadable design: computation generate the out as in the same order of the input. This make computation block cascadable. For example in a larger FPGA, we can put two computation block one after another. This will increase the throughput by more than 2 times.

\item Compact size: computation block contains few collection of layers though it is compact in size and can be accomodated small FPGA too. So computation block can be a general solution across different devices.

\end{itemize}

\subsection{Architecture}
%Number equations consecutively. To make your 
%equations more compact, you may use the solidus (~/~), the exp function, or 
%appropriate exponents. Italicize Roman symbols for quantities and variables, 
%but not Greek symbols. Use a long dash rather than a hyphen for a minus 
%sign. Punctuate equations with commas or periods when they are part of a 
%sentence, as in:
%\begin{equation}
%a+b=\gamma\label{eq}
%\end{equation}
%
%Be sure that the 
%symbols in your equation have been defined before or immediately following 
%the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
%the beginning of a sentence: ``Equation \eqref{eq} is . . .''

\subsection{Implementation}
\subsubsection{Functional flow}
First we have to train the CNN model using TensorFlow or any framework. Its better to use SqueezeNet like models will achieve highest efficiency in our architecture. Then carefully select the floating point representation required for the trained model. Then convert trained weights and bias parameters to custom floating point values using provided APIs. This initial part can be done offshore in servers. Now converted parameters handed over to ARM processor in SoC FPGA. A host program also compiled and loaded in processor. Host program load the parameter in memory and send the address to FPGA, so it can access parameters. Then host program generates the configuration parameters required to execute particular CNN model and send it to configuration controller in FPGA. After initializing, it will start to load the input images into memory and pass the address to FPGA. 
In FPGA, configuration controller reads configurations and distributes to all other modules (input layer, output layer, kernel loader, computation block). Eventually, it will set all the required configuration registers in these modules. configuration controller issue a "start" signal to all blocks. Now weights and input data are read from memory and feeded to kernel controller and input layer modules. They will rearrange the order as required by computation block. Then computation block process the data according to configurations. Output from computation block send to output layer module which will write the output to memory. Again in next iteration input are read from memory and configuration block is executed with another configuration. This loop continues until it reaches the final layer. After the final iteration, configuration controller generate a interrupt to host programme denoting that inference have completed. Now host program can access the output of inference and use it to perform higher level task. 

%Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
%of ``hard'' references (e.g., \verb|(1)|). That will make it possible
%to combine sections, add equations, or change the order of figures or
%citations without having to go through the file line by line.
%
%Please don't use the \verb|{eqnarray}| equation environment. Use
%\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
%environment leaves unsightly spaces around relation symbols.
%
%Please note that the \verb|{subequations}| environment in {\LaTeX}
%will increment the main equation counter even when there are no
%equation numbers displayed. If you forget that, you might write an
%article in which the equation numbers skip from (17) to (20), causing
%the copy editors to wonder if you've discovered a new method of
%counting.
%
%{\BibTeX} does not work by magic. It doesn't get the bibliographic
%data from thin air but from .bib files. If you use {\BibTeX} to produce a
%bibliography you must send the .bib files. 
%
%{\LaTeX} can't read your mind. If you assign the same label to a
%subsubsection and a table, you might find that Table I has been cross
%referenced as Table IV-B3. 
%
%{\LaTeX} does not have precognitive abilities. If you put a
%\verb|\label| command before the command that updates the counter it's
%supposed to be using, the label will pick up the last counter to be
%cross referenced instead. In particular, a \verb|\label| command
%should not go before the caption of a figure or a table.
%
%Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
%will not stop equation numbers inside \verb|{array}| (there won't be
%any anyway) and it might stop a wanted equation number in the
%surrounding equation.

\subsection{Some Common Mistakes}\label{SCM}
\begin{itemize}
\item The word ``data'' is plural, not singular.
\item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
\item Do not confuse ``imply'' and ``infer''.
\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
\item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
\end{itemize}
An excellent style manual for science writers is \cite{b7}.

\subsection{Authors and Affiliations}
\textbf{The class file is designed for, but not limited to, six authors.} A 
minimum of one author is required for all conference articles. Author names 
should be listed starting from left to right and then moving down to the 
next line. This is the author sequence that will be used in future citations 
and by indexing services. Names should not be listed in columns nor group by 
affiliation. Please keep your affiliations as succinct as possible (for 
example, do not differentiate among departments of the same organization).

\subsection{Identify the Headings}
Headings, or heads, are organizational devices that guide the reader through 
your paper. There are two types: component heads and text heads.

Component heads identify the different components of your paper and are not 
topically subordinate to each other. Examples include Acknowledgments and 
References and, for these, the correct style to use is ``Heading 5''. Use 
``figure caption'' for your Figure captions, and ``table head'' for your 
table title. Run-in heads, such as ``Abstract'', will require you to apply a 
style (in this case, italic) in addition to the style provided by the drop 
down menu to differentiate the head from the text.

Text heads organize the topics on a relational, hierarchical basis. For 
example, the paper title is the primary text head because all subsequent 
material relates and elaborates on this one topic. If there are two or more 
sub-topics, the next level head (uppercase Roman numerals) should be used 
and, conversely, if there are not at least two sub-topics, then no subheads 
should be introduced.

\subsection{Figures and Tables}
\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
bottom of columns. Avoid placing them in the middle of columns. Large 
figures and tables may span across both columns. Figure captions should be 
below the figures; table heads should appear above the tables. Insert 
figures and tables after they are cited in the text. Use the abbreviation 
``Fig.~\ref{fig}'', even at the beginning of a sentence.

\begin{table}[htbp]
\caption{Table Type Styles}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
\cline{2-4} 
\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
\hline
copy& More table copy$^{\mathrm{a}}$& &  \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
\end{tabular}
\label{tab1}
\end{center}
\end{table}

%\begin{figure}[htbp]
%\centerline{\includegraphics{fig1.png}}
%\caption{Example of a figure caption.}
%\label{fig}
%\end{figure}

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
rather than symbols or abbreviations when writing Figure axis labels to 
avoid confusing the reader. As an example, write the quantity 
``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
units in the label, present them within parentheses. Do not label axes only 
with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
quantities and units. For example, write ``Temperature (K)'', not 
``Temperature/K''.

\section*{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without 
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
acknowledgments in the unnumbered footnote on the first page.

\section*{References}

Please number citations consecutively within brackets \cite{b1}. The 
sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

Number footnotes separately in superscripts. Place the actual footnote at 
the bottom of the column in which it was cited. Do not put footnotes in the 
abstract or reference list. Use letters for table footnotes.

Unless there are six authors or more give all authors' names; do not use 
``et al.''. Papers that have not been published, even if they have been 
submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
Capitalize only the first word in a paper title, except for proper nouns and 
element symbols.

For papers published in translation journals, please give the English 
citation first, followed by the original foreign-language citation \cite{b6}.

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\end{thebibliography}

\end{document}
